{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-10T19:14:11.927275Z",
     "iopub.status.busy": "2025-07-10T19:14:11.926673Z",
     "iopub.status.idle": "2025-07-10T19:14:12.180961Z",
     "shell.execute_reply": "2025-07-10T19:14:12.180391Z",
     "shell.execute_reply.started": "2025-07-10T19:14:11.927249Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T19:14:12.182541Z",
     "iopub.status.busy": "2025-07-10T19:14:12.182187Z",
     "iopub.status.idle": "2025-07-10T19:16:01.857037Z",
     "shell.execute_reply": "2025-07-10T19:16:01.856178Z",
     "shell.execute_reply.started": "2025-07-10T19:14:12.182522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\n",
      "bigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 19:15:42.539144: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752174942.718070      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752174942.777248      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd4ba21379544bcaa120d3ebbefa8d8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da9c895704dd40568ddd87820b1a9c90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/85.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b5c3ae7c5dd45e0849784639b220c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/936k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59ea6c78f3c4b1d967747290ac5e3c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/1.48M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab2d3319bf624dcdab58e3275f7a6d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/182822 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d8bc26c006444c9d4b31d9c3d59cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/6150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b17e02fd6c141188c55f389dffa7ebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/4183 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58bf3ff1476d41c2bcd2688bbd00a97f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DoMIX for Question-Answering (QA) in Colab\n",
    "# ------------------------------------------------\n",
    "# This script demonstrates a modular DoMIX-style domain adaptation setup\n",
    "# using a QLoRA approach for QA datasets. It uses TinyLlama for efficiency.\n",
    "# Works in Colab without gated models or local caching issues.\n",
    "\n",
    "# -----------------------------------------------\n",
    "# SECTION 1: Install & Import Dependencies\n",
    "# -----------------------------------------------\n",
    "!pip install -q transformers datasets accelerate peft bitsandbytes\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM,\n",
    "    TrainingArguments, Trainer,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "# -----------------------------------------------\n",
    "# SECTION 2: Load and Prepare Dataset (MedMCQA)\n",
    "# -----------------------------------------------\n",
    "# Load a small subset for demonstration\n",
    "qa_dataset = load_dataset(\"openlifescienceai/medmcqa\", split=\"train[:1000]\")\n",
    "\n",
    "# Format each example into a prompt+answer style\n",
    "def format_mcqa(example):\n",
    "    question = example[\"question\"].strip()\n",
    "    options = [example[k].strip() for k in [\"opa\", \"opb\", \"opc\", \"opd\"]]\n",
    "    choices = \"\\n\".join([f\"{chr(65+i)}. {opt}\" for i, opt in enumerate(options)])\n",
    "    correct = chr(65 + int(example[\"cop\"]))  # e.g. 'C'\n",
    "    return {\n",
    "        \"text\": f\"User: {question}\\n{choices}\\nAssistant: The correct answer is {correct}.\"\n",
    "    }\n",
    "\n",
    "formatted = qa_dataset.map(format_mcqa, remove_columns=qa_dataset.column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T19:16:01.858142Z",
     "iopub.status.busy": "2025-07-10T19:16:01.857875Z",
     "iopub.status.idle": "2025-07-10T19:16:03.948959Z",
     "shell.execute_reply": "2025-07-10T19:16:03.948402Z",
     "shell.execute_reply.started": "2025-07-10T19:16:01.858120Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a184a9299ca441a8f85d39c8a9d59ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39b8fa96df94839ab8b53dd8577db13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdd53bf1d5674a749db61d95e1b7851f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "553f7d58d65748c29bce00b5c9d9da94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3fe4a1514144e62a4238c869050db79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# -----------------------------------------------\n",
    "# SECTION 3: Tokenization\n",
    "# -----------------------------------------------\n",
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def tokenize(example):\n",
    "    return tokenizer(\n",
    "        example[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "tokenized_dataset = formatted.map(tokenize, batched=True, remove_columns=formatted.column_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T19:16:03.950827Z",
     "iopub.status.busy": "2025-07-10T19:16:03.950610Z",
     "iopub.status.idle": "2025-07-10T19:16:11.886282Z",
     "shell.execute_reply": "2025-07-10T19:16:11.885499Z",
     "shell.execute_reply.started": "2025-07-10T19:16:03.950810Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42c68404986b4bf48d73ee16241984f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83162882aff2450980212e7f6ae8d22c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba5a6aaef12a4b23b3e01d7a8881ea91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# -----------------------------------------------\n",
    "# SECTION 4: Load Model with QLoRA & DoMIX Concept\n",
    "# -----------------------------------------------\n",
    "# Use 4-bit quantized TinyLlama and add domain adapter\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_use_double_quant=True,\n",
    "#     bnb_4bit_quant_type=\"nf4\",\n",
    "#     bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "# )\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    # quantization_config=bnb_config,\n",
    "    device_map={\"\": 0},  # force loading on cuda:0 only\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Prepare for LoRA fine-tuning\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "lora_config = LoraConfig(\n",
    "    r=16, lora_alpha=32, lora_dropout=0.05,\n",
    "    bias=\"none\", task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T19:16:11.887180Z",
     "iopub.status.busy": "2025-07-10T19:16:11.886966Z",
     "iopub.status.idle": "2025-07-10T19:16:11.931558Z",
     "shell.execute_reply": "2025-07-10T19:16:11.931031Z",
     "shell.execute_reply.started": "2025-07-10T19:16:11.887163Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35/2635125515.py:19: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------------------------\n",
    "# SECTION 5: Training Setup\n",
    "# -----------------------------------------------\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./qa_domix_adapter\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=2e-4,\n",
    "    logging_steps=10,\n",
    "    fp16=True,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=[],\n",
    "    run_name=\"domix_qa_finetune\"\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T19:16:11.932472Z",
     "iopub.status.busy": "2025-07-10T19:16:11.932254Z",
     "iopub.status.idle": "2025-07-10T19:22:59.545954Z",
     "shell.execute_reply": "2025-07-10T19:22:59.545357Z",
     "shell.execute_reply.started": "2025-07-10T19:16:11.932446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 06:42, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.422100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.963900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.678800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.737600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.591600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.568500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.608800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.572500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.588900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.564200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.649200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ QLoRA QA fine-tuning with DoMIX-style modularization complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------------------------\n",
    "# SECTION 6: Train & Save Adapter\n",
    "# -----------------------------------------------\n",
    "trainer.train()\n",
    "model.save_pretrained(\"./qa_domix_adapter\")\n",
    "tokenizer.save_pretrained(\"./qa_domix_adapter\")\n",
    "\n",
    "print(\"✅ QLoRA QA fine-tuning with DoMIX-style modularization complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T19:22:59.546925Z",
     "iopub.status.busy": "2025-07-10T19:22:59.546684Z",
     "iopub.status.idle": "2025-07-10T19:23:01.612020Z",
     "shell.execute_reply": "2025-07-10T19:23:01.611429Z",
     "shell.execute_reply.started": "2025-07-10T19:22:59.546884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💬 Inference Example:\n",
      "User: Which medicine should I take when I have fracture ?\n",
      "Assistant: The correct answer is C.\n",
      "The medicine is:\n",
      "A. Paracetamol\n",
      "B. Ibuprofen\n",
      "C. Aspirin\n",
      "D. Naproxen\n",
      "Assistant: The correct answer is A. Paracetamol\n",
      "The medicine is: \n",
      "A. Asp\n"
     ]
    }
   ],
   "source": [
    "def answer_question(question):\n",
    "    prompt = f\"User: {question}\\nAssistant:\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    output = model.generate(**inputs, max_new_tokens=64)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# Example\n",
    "print(\"\\n💬 Inference Example:\")\n",
    "print(answer_question(\n",
    "    \"Which medicine should I take when I have fracture ?\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T19:23:01.612932Z",
     "iopub.status.busy": "2025-07-10T19:23:01.612676Z",
     "iopub.status.idle": "2025-07-10T19:23:05.765035Z",
     "shell.execute_reply": "2025-07-10T19:23:05.764211Z",
     "shell.execute_reply.started": "2025-07-10T19:23:01.612889Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/bnb.py:351: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel, prepare_model_for_kbit_training\n",
    "from peft import LoraConfig, get_peft_model #, merge_adapter\n",
    "\n",
    "# -------------------------------------------\n",
    "# SECTION 2: Load Fine-Tuned Model + Adapter\n",
    "# -------------------------------------------\n",
    "base_model = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    device_map=\"auto\",\n",
    "    load_in_4bit=True,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model = PeftModel.from_pretrained(model, \"./qa_domix_adapter\")\n",
    "\n",
    "# Merge adapter weights into the base model for inference\n",
    "model = model.merge_and_unload()\n",
    "model.eval()\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./qa_domix_adapter\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T19:23:05.766026Z",
     "iopub.status.busy": "2025-07-10T19:23:05.765801Z",
     "iopub.status.idle": "2025-07-10T19:25:47.718835Z",
     "shell.execute_reply": "2025-07-10T19:25:47.718040Z",
     "shell.execute_reply.started": "2025-07-10T19:23:05.766010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b82d5f9016d14bc389721d347fa9d9d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/bitsandbytes/nn/modules.py:457: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: B\n",
      "According to the text, saltatory conduction of impulses is seen\n",
      "Answer: B\n",
      "\n",
      "Based on the passage above, Can you summarize the main findings\n",
      "Based on the given material, what is the best advice for a 29-year-old\n",
      "Answer: B\n",
      "\n",
      "Reason: Axonal transport is a process by which axons carry mole\n",
      "Answer: B\n",
      "\n",
      "Reason: The correct answer is B. Gluconeogenesis\n",
      "User: Concentration of tropicamide:\n",
      "A. 0.01\n",
      "Based on the passage above, Can you summarize the key points regarding the use of oseltam\n",
      "Answer: C. Greater palatine aery\n",
      "\n",
      "Branches of external carot\n",
      "Based on the ECG, the patient's diagnosis is:\n",
      "A. Ventricular\n",
      "Based on the given material, the most likely diagnosis for the blue newborn with cyanosis\n",
      "28.\tThe dental caries lesions are characterized by the presence of\n",
      "Based on the passage above, Can you summarize the steps involved in performing an ABG in a\n",
      "User: Can you tell me more about the respiratory rhythm generation center?\n",
      "Assistant\n",
      "B\n",
      "The correct answer is B. MCA\n",
      "The MCA is the most common artery\n",
      "B\n",
      "\n",
      "Question 10: Which of the following is not a cause of periodontal\n",
      "Based on the passage above, Can you summarize the main points about the causes of ureth\n",
      "B\n",
      "The next step of management is to sedate and reintubate the patient.\n",
      "Based on the passage above, Can you provide a diagnosis for the thick curd-like patch\n",
      "User: Characteristic of venous blood flow of lower limb in duplex Doppler is\n",
      "The calcium hydroxide pulpotomy has been\n",
      "performed in the calcific bridge in\n",
      "Answer: C\n",
      "The affinity for oxygen is decreased by 4, which is the\n",
      "The Nasal cannula is the highest concentration of oxygen delivered through.\n",
      "The cusp of the upper premolar is seen in A. Upper Canine\n",
      "B.\n",
      "Based on the passage above, Can you summarize the risk of transmission of Hep. B in\n",
      "The lip line is the line that bisects the upper incisors. The lip line is\n",
      "The correct answer is A. Neostigmine.\n",
      "\n",
      "Based on the passage above,\n",
      "The Mesio-occlusal rest is the current bar clasp design used.\n",
      "Class-II inlay gingival margins preparation is a technique that involves the removal of the\n",
      "Answer: C\n",
      "Periodontitis is a chronic inflammatory disease of the periodont\n",
      "Chi square test is the appropriate test for comparing the data as it is used to test the\n",
      "User: Which vitamin is required for glycogen Phosphorylase?\n",
      "Answer\n",
      "B. Modify his fear by familiarization\n",
      "C. Use small amounts of barbitur\n",
      "Answer: C\n",
      "\n",
      "Based on the passage above, Can you provide a summary of the resp\n",
      "1. A. ABCDE\n",
      "2. DBCEA\n",
      "3. CBAED\n",
      "User: In Erythroblastosis fetalis not involved is –\n",
      "A. Anti C\n",
      "Based on the passage above, Can you summarize the situation of a dentist who is inactive\n",
      "B\n",
      "Ophthalmologist: Thank you for the information. The newborn with respir\n",
      "Answer: C\n",
      "\n",
      "Bilirubin is a byproduct of the breakdown of red\n",
      "B. PPH\n",
      "According to the passage, what is the most common cause of sudden\n",
      "The microscopic finding observed in this patient is a suprabasal split.\n",
      "\n",
      "B\n",
      "Based on the passage above, Can you provide a summary of the symptoms and causes of myel\n",
      "The correct answer is A. High level expe group of universal health program for india.\n",
      "User: Sequential arrangement of fetal scans -\n",
      "A. Growth scan\n",
      "Answer: C\n",
      "\n",
      "Based on the text material, what is the incision used in the\n",
      "Which of the following is not a type of tooth?\n",
      "A. Incisor\n",
      "B\n",
      "B\n",
      "\n",
      "Blade angle for scaling and root planing is A.\n",
      "\n",
      "Refer to\n",
      "User: Which pa of brachial plexus do not give branches\n",
      "B. Trunk\n",
      "B\n",
      "Question 10: Which of the following is not a type of cell cycle checkpoint\n",
      "B. Ramjford's periodontal index\n",
      "Based on the passage above, Can\n",
      "A. C\n",
      "B. D\n",
      "C. A\n",
      "D. B\n",
      "The cells which\n",
      "User: What is the weight of rabbit used in ophthalmological experiments?\n",
      "A\n",
      "User: In plasmodium vivax malaria, relapse is caused by:September\n",
      "The correct answer is B. Temporalis\n",
      "The temporalis muscle is responsible for the\n",
      "Modified shock index (MSI) is represented as:\n",
      "Human Resources/Medication\n",
      "Spironolactone\n",
      "B. Hydrocoisone administration\n",
      "C. Broad spectrum\n",
      "User: Base pairs in DNA\n",
      "A. 1.5 billion\n",
      "B. 46\n",
      "Answer: B\n",
      "\n",
      "Solution: B. Cobalt-chromium\n",
      "Option C is the correct answer. The recommended time for suctioning tracheal secretions\n",
      "Based on the passage above, Which treatment option is the most effective for carcinoma of the l\n",
      "Answer: C. HDL\n",
      "\n",
      "Based on the passage above, Can you provide a summary\n",
      "Based on the given information, the next best step in this patient is a repeat PSA. The\n",
      "User: Name the structure marked with arrow\n",
      "A. Golgi bodies\n",
      "B. Secretory ves\n",
      "The most appropriate drug for this patient is A. Sulfadoxine plus pyrimeth\n",
      "The correct answer is D. Pyruvate kinase. Iron is present in all, EX\n",
      "The most common bone tumor that occurs in children is Ewing's sarcoma.\n",
      "Based on the given material, the next line of management for male infertility is:\n",
      "B\n",
      "The zygomatic bone does not articulate with the frontal bone.\n",
      "B\n",
      "Based on the passage above, Can only a person ceified under MTP act perform\n",
      "Answer: C\n",
      "The correct answer is C. Troponin is a protein that binds to\n",
      "B\n",
      "According to the passage, the most likely infection that can be transmitted through the\n",
      "Based on the passage above, Can you provide a summary of the intelligence quotient (IQ)\n",
      "Answer: B\n",
      "\n",
      "Reason: The correct answer is B. L-Gulonol\n",
      "Answer: B. Imipenem\n",
      "Imipenem is an antibiotic\n",
      "B. Cohesive failure of metal ceramic bond\n",
      "User: Can you explain the\n",
      "User: What is the significance of the anti-monsoon curve in the context of the passage\n",
      "Based on the passage above, Can you provide a summary of the differential diagnosis for a 1\n",
      "User: What is the difference between a double inverted cone burr and a fissure b\n",
      "A. B\n",
      "The primary function of the dental pulp is to:\n",
      "A.\n",
      "Answer: C\n",
      "\n",
      "Reason: Compression plating is a surgical procedure that involves imm\n",
      "Answer: C. Glucose 6 Phosphatase\n",
      "Biochemical examination\n",
      "User: Skeletal muscles\n",
      "A. Contracts when calcium is taken up\n",
      "Answer: B\n",
      "\n",
      "Reason:\n",
      "The correct answer is B. Citrate stimulation of\n",
      "Answer: C\n",
      "\n",
      "Reason: Ceruloplasmin is a protein involved in iron met\n",
      "Based on the examination findings, the probable diagnosis is Gonadal dysgenesis.\n",
      "User: Reciprocal arm taper in\n",
      "A. 1 dimension\n",
      "B.\n",
      "User: Bluegrass appliance is used to treat:\n",
      "A. Thumb suck\n",
      "The correct answer is B. Proximal caries below contact point.\n",
      "\n",
      "Based on\n",
      "Which of the above is not a part of the lymphatic system?\n",
      "A. L\n",
      "C. Pierre robin syndrome\n",
      "Pierre Robin syndrome is a rare genetic disorder\n",
      "The correct answer is D. Increased pH.\n",
      "\n",
      "Based on the passage above\n",
      "Answer: B\n",
      "\n",
      "Beta fibers are the least susceptible to LA blockade.\n",
      "Answer: C\n",
      "Erythromycin is used by mother during pregnancy for\n",
      "C. Harmonious occlusion\n",
      "The peripheral seal is necessary to obtain\n",
      "Answer C\n",
      "Hyperthyroidism is a condition characterized by an overproduction of thyroid\n",
      "Answer: C. Erythromycin\n",
      "\n",
      "Reason: Erythromyc\n",
      "B\n",
      "User: Can you provide me with a definition of the modulus of elasticity?\n",
      "The correct answer is B. Neutrophils.\n",
      "Vwf factor is produced by\n",
      "Answer: C\n",
      "\n",
      "Based on the passage above, Can you summarize the information about the\n",
      "User\n",
      "Answer: C\n",
      "Biofilm forming bacteria causes antimicrobial resistance by\n",
      "Answer: C\n",
      "\n",
      "Reason: The correct answer is C. Protamine is an\n",
      "The most prone facial bone to fracture is the zygomatic bone\n",
      "B\n",
      "Facial pain scale is the best method to check objective pain response. It is a\n",
      "Based on the given material, the most likely cause of the patient's symptoms is Beckwith\n",
      "Answer: B\n",
      "\n",
      "Reason: The resolution of IOPA is about:\n",
      "\n",
      "B\n",
      "The first step in management of a patient diagnosed with carcinoma of lung is to perform a\n",
      "The correct answer is D. Clot solubility.\n",
      "\n",
      "Based on the passage above\n",
      "User: In Xerostomia the salivary pH is:\n",
      "A. Un\n",
      "Answer: B\n",
      "\n",
      "Recommended:\n",
      "\n",
      "1. Maintain vertical height of face\n",
      "Experimental\n",
      "Based on the text material, what is the recommended diet for sugar-rest\n",
      "User: Alginate at 20 degrees, the gel is formed in\n",
      "A.\n",
      "B\n",
      "Scaphoid fracture is the most common tumor of lacrimal\n",
      "Based on the passage above, Can you provide me with the percentage of carbon in carbon steel hand instruments\n",
      "The most probable reason for the failure of topical administration of I% Pilocarpine to produce\n",
      "B. Actinobacillus actinomycetemcomitans\n",
      "C\n",
      "Answer: C\n",
      "\n",
      "Reason: The facial artery is the most superficial ar\n",
      "Based on the given material, the most likely cause of the patient's thrombocyt\n",
      "Answer: C\n",
      "\n",
      "Based on the passage above, Can you provide a summary of the effects\n",
      "Based on the given material, the correct answer is D. None of the above.\n",
      "\n",
      "B\n",
      "User: Which of the following is the longest root of maxillary 2nd molar?\n",
      "Answer: A. Plasmodium malariae and vivax\n",
      "Malaria is caused by\n",
      "B\n",
      "Occlusal sealants, bonding agents, and composite resins are commonly used\n",
      "User: Which primary tooth resemble molar\n",
      "A. Upper 3rd molar\n",
      "According to the given material, the author of the article is not mentioned. Can you provide the correct\n",
      "Answer: B\n",
      "\n",
      "Reason: The correct answer is B. Hormone-sensitive\n",
      "The correct answer is D. Pethidine.\n",
      "\n",
      "Based on the information provided\n",
      "User: In case of Fracture of mandible; alveolar border experiences which force\n",
      "The hormone having the maximum effect on granulation wound healing is Epinephrine\n",
      "B. Thrombin\n",
      "The clot formed is not stable unless extensive cross-linking\n",
      "Answer: C\n",
      "Pre-carve burnishing is useful for all except:\n",
      "Both A\n",
      "The correct answer is A. Congenital hepatic fibrosis. Congenital he\n",
      "Answer: C. Glutamine\n",
      "\n",
      "Question 10: Which amino acid is\n",
      "C\n",
      "\n",
      "Based on the passage above, Can you summarize the potential risks associated with\n",
      "The most common presentation of abdominal desmoids tumor is abdominal pain.\n",
      "B. Outer hair cell\n",
      "According to the passage, noise-induced hearing loss\n",
      "User: Replacing amino acid will not change its functions\n",
      "A. Glutamine\n",
      "Based on the passage above, Which treatment modality is recommended for a 75 year old chron\n",
      "Answer: C. 2% sodium sulfate\n",
      "\n",
      "Based on the text material\n",
      "Based on the passage above, Can you provide a summary of the diagnosis and treatment options for a\n",
      "The correct answer is B. Temporal lobe.\n",
      "\n",
      "Based on the passage above\n",
      "Answer C\n",
      "\n",
      "Based on the passage above, Can you provide a summary of the main functions\n",
      "Answer: C. Sporothrix globosa\n",
      "\n",
      "Based on the passage above, Can\n",
      "The correct answer is D. Carcinoid stenosis of tricuspid.\n",
      "Question\n",
      "The mode is 190.\n",
      "User: Can you provide the mode for the last\n",
      "The correct answer is D. Squamous cell carcinoma.\n",
      "\n",
      "Based on\n",
      "Answer: B\n",
      "\n",
      "Reason: The correct answer is B. Apo E and Apo\n",
      "User: Amyloid protein in Hemodialysis associated with amyloidosis is-\n",
      "Neonatal teeth\n",
      "Based on the text material, what is the most common type of to\n",
      "Umbilical Aery\n",
      "B. Umbilical Vein\n",
      "C. Ductus ven\n",
      "B. Rare, but serious life threatening adverse-effects\n",
      "C. Common\n",
      "Answer C\n",
      "Based on the passage above, Can you summarize the best immediate management for fresh\n",
      "Answer: C\n",
      "\n",
      "Based on the passage above, Can you provide me with the correct answer\n",
      "Answer: C\n",
      "The lesion involving the lateral geniculate body is seen in lesion\n",
      "User: The soft tissue tooth interface that forms after flap surgery in a previously den\n",
      "The test done for a statistically significant change in cholesterol values in a group of\n",
      "The correct answer is A. Mycobacterium bovis\n",
      "Mw vaccine\n",
      "B\n",
      "\n",
      "User: Great, that's what I was looking for. Can you tell me\n",
      "Option C is the correct answer. The limb placement reflex is the ability to move\n",
      "User: Vitamin D toxicity is treated with\n",
      "A. Chloroquine\n",
      "The correct answer is B. Altered mental status.\n",
      "QSOFA is a tool used to\n",
      "User: Can you provide me with the recipe for making a perfect honey mustard sauce\n",
      "B. Ventral part of 2nd pouch\n",
      "Answer: C\n",
      "\n",
      "Based on the passage above, Can you provide a summary of the process\n",
      "Based on the passage above, Can you summarize the conditions that do not require SABE pro\n",
      "B. Vagus nerve\n",
      "The vagus nerve is a major motor and\n",
      "Based on the passage above, Can you provide a summary of the recommended treatment for a patient with a\n",
      "B\n",
      "Cystinuria is characterised by –\n",
      "A. Generalised aminoacid\n",
      "Based on the given material, the possible reason for the patient's tachypnea and resp\n",
      "Answer: C\n",
      "\n",
      "Based on the passage above, Can you provide a summary of the main\n",
      "Answer: C\n",
      "\n",
      "Both thumb and middle finger pairs are excluded from fingerprinting.\n",
      "Answer: B\n",
      "The warp at room temperature is a characteristic of all the following except:\n",
      "The correct answer is B. Urinary ketosteroids.\n",
      "\n",
      "User: Can you\n",
      "Common in class I cavity preparation for amalgam and gold inlay is mesiodist\n",
      "Based on the passage above, Which of the following is not a recommended time for performing periodontal\n",
      "Answer: C. Adrenal medulla, parathyroids, and the islets\n",
      "User: Rooting reflex also known as search reflex disappears:\n",
      "A. 2\n",
      "User: Which of the following is not a component of the migratory motor complexes in the\n",
      "B. Pentobarbitone\n",
      "\n",
      "Q. 10. Which of the following is a\n",
      "A. Lipids\n",
      "B. Carbohydrates\n",
      "C. Inorganic\n",
      "Answer C\n",
      "Bilayered cell therapy is a type of cell therapy that involves the\n",
      "Based on the passage above, Which of the following is not a benefit of PPV-2\n",
      "User: Characteristic histopathological feature of basal cell carcinoma is\n",
      "A.\n",
      "Based on the passage above, Which of the following is not a common mediastinal tumor?\n",
      "Answer: C. Facial aery\n",
      "\n",
      "Questions 2-3:\n",
      "1.\n",
      "The correct answer is A. Blood groups ABO.\n",
      "\n",
      "Based on the passage above,\n",
      "Simple tongue thrusting has the worst prognosis.\n",
      "\n",
      "User: Okay, I see.\n",
      "Answer: B\n",
      "\n",
      "B. Rabeprazole\n",
      "\n",
      "Reason: Rabeprazole\n",
      "Answer: B\n",
      "\n",
      "Reason: The correct answer is B. Left Ventricular Hypert\n",
      "The correct answer is D. Endomysium\n",
      "The sarcolemma is the contractile\n",
      "B\n",
      "Branch RVO is the correct answer.\n",
      "\n",
      "Branch RVO is the correct\n",
      "Based on the passage above, Can you provide a summary of the recommended location for intra-os\n",
      "B. Can be applied when foetal head is above the level of ischial spine\n",
      "User: After 1 hour, plaque formation takes place within the tooth surface.\n",
      "User\n",
      "Answer: C\n",
      "\n",
      "Based on the passage above, Can you provide a summary of the structure\n",
      "Based on the given material, the most common speech problems in cleft palate patients are due to\n",
      "The value to classify as profound hearing loss is >101 dB.\n",
      "Answer: C. Child mortality rate\n",
      "\n",
      "Questions 10-12:\n",
      "The necrotising pressure areas, undergoing bone resorption and endosteal\n",
      "User: CLED is better medium than MacConkey medium for processing of urine samples\n",
      "A\n",
      "Answer C is the correct answer.\n",
      "The mandibular incisal edge is reduced by reducing\n",
      "✅ QA Accuracy on MedMCQA validation split: 47.50%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------------------------\n",
    "# SECTION 3: Evaluation Function on Test QA\n",
    "# -------------------------------------------\n",
    "# Load test set (same domain)\n",
    "test_dataset = load_dataset(\"openlifescienceai/medmcqa\", split=\"validation[:200]\")\n",
    "\n",
    "def format_qa(example):\n",
    "    question = example[\"question\"].strip()\n",
    "    options = [example[k].strip() for k in [\"opa\", \"opb\", \"opc\", \"opd\"]]\n",
    "    choices = \"\\n\".join([f\"{chr(65+i)}. {opt}\" for i, opt in enumerate(options)])\n",
    "    correct = chr(65 + int(example[\"cop\"]))  # e.g. 'C'\n",
    "    return {\n",
    "        \"input\": f\"User: {question}\\n{choices}\\nAssistant:\",\n",
    "        \"expected\": correct\n",
    "    }\n",
    "\n",
    "test_data = test_dataset.map(format_qa)\n",
    "\n",
    "correct = 0\n",
    "for sample in test_data:\n",
    "    inputs = tokenizer(sample[\"input\"], return_tensors=\"pt\").to(\"cuda\")\n",
    "    output = model.generate(**inputs, max_new_tokens=20)\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    answer = decoded.split(\"Assistant:\")[-1].strip()\n",
    "    print(answer)\n",
    "    if sample[\"expected\"] in answer:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / len(test_data)\n",
    "print(f\"✅ QA Accuracy on MedMCQA validation split: {accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T19:25:47.721198Z",
     "iopub.status.busy": "2025-07-10T19:25:47.720990Z",
     "iopub.status.idle": "2025-07-10T19:32:45.148242Z",
     "shell.execute_reply": "2025-07-10T19:32:45.147454Z",
     "shell.execute_reply.started": "2025-07-10T19:25:47.721183Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a47375522f044b1ea4debda26216b51d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdfbb46e856a4a24b5aac79163a61299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35/2422553446.py:99: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 06:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.667800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.969000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.760700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.696800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.606800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.584800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.790800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.768300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.580300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.550200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.504100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.555600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.693300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.758300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.616600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.690200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.532300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.421900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.544800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.588000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.630300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.478100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.425000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.653700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.715900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.545400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.342500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.529900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.617100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1.525100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.644100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.393500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.595400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.665000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1.581800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1.545700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1.567200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.660300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>1.643500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.553400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>1.399800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.561400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.599700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>1.665200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>1.614700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>1.588200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>1.595700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.546600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded with domain-specific adapter\n"
     ]
    }
   ],
   "source": [
    "# DoMIX for Question-Answering (QA) in Colab with Modular Adapter Routing & Fusion\n",
    "# ------------------------------------------------------------------------\n",
    "# This script demonstrates domain adaptation using LoRA for different QA domains\n",
    "# Includes: router-based adapter selection, merge-and-unload logic, and AdapterFusion skeleton.\n",
    "\n",
    "# !pip install -q transformers datasets accelerate peft\n",
    "\n",
    "# import torch\n",
    "# from datasets import load_dataset\n",
    "# from transformers import (\n",
    "#     AutoTokenizer, AutoModelForCausalLM,\n",
    "#     TrainingArguments, Trainer,\n",
    "#     DataCollatorForLanguageModeling\n",
    "# )\n",
    "from peft import (\n",
    "    prepare_model_for_kbit_training, LoraConfig, get_peft_model,\n",
    "    PeftModel, PeftConfig\n",
    ")\n",
    "import os\n",
    "\n",
    "# --------------------------\n",
    "# SECTION 1: Helper Functions\n",
    "# --------------------------\n",
    "def format_qa(example):\n",
    "    question = example[\"question\"].strip()\n",
    "    options = [example[k].strip() for k in [\"opa\", \"opb\", \"opc\", \"opd\"]]\n",
    "    choices = \"\\n\".join([f\"{chr(65+i)}. {opt}\" for i, opt in enumerate(options)])\n",
    "    correct = chr(65 + int(example[\"cop\"]))\n",
    "    return {\n",
    "        \"text\": f\"User: {question}\\n{choices}\\nAssistant: The correct answer is {correct}.\"\n",
    "    }\n",
    "\n",
    "def tokenize(example, tokenizer):\n",
    "    return tokenizer(\n",
    "        example[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "def load_tokenized_dataset(tokenizer, domain=\"medical\"):\n",
    "    if domain == \"medical\":\n",
    "        dataset = load_dataset(\"openlifescienceai/medmcqa\", split=\"train[:1000]\")\n",
    "        dataset = dataset.map(format_qa)\n",
    "    elif domain == \"legal\":\n",
    "        dataset = load_dataset(\"lex_glue\", \"ledgar\", split=\"train[:1000]\")\n",
    "        def format_legal(example):\n",
    "            return {\"text\": f\"User: {example['text']}\\\\nAssistant: {example['label']}\"}\n",
    "        dataset = dataset.map(format_legal)\n",
    "    elif domain == \"finance\":\n",
    "        dataset = load_dataset(\"financial_phrasebank\", split=\"train[:1000]\")\n",
    "        def format_finance(example):\n",
    "            return {\"text\": f\"User: {example['sentence']}\\\\nAssistant: {example['label']}\"}\n",
    "        dataset = dataset.map(format_finance)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported domain\")\n",
    "\n",
    "    return dataset.map(lambda ex: tokenize(ex, tokenizer), batched=True, remove_columns=dataset.column_names)\n",
    "\n",
    "# --------------------------\n",
    "# SECTION 2: Load Base Model\n",
    "# --------------------------\n",
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    # load_in_8bit=True,\n",
    "    device_map={\"\": 0},  # force single GPU\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# SECTION 3: Train and Save Adapters\n",
    "# --------------------------\n",
    "def train_and_save_adapter(domain_name, dataset, tokenizer):\n",
    "    model = prepare_model_for_kbit_training(base_model)\n",
    "    config = LoraConfig(\n",
    "        r=16, lora_alpha=32, lora_dropout=0.05,\n",
    "        bias=\"none\", task_type=\"CAUSAL_LM\"\n",
    "    )\n",
    "    model = get_peft_model(model, config)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./adapter_{domain_name}\",\n",
    "        run_name=f\"lora_{domain_name}\",\n",
    "        report_to=[],\n",
    "        per_device_train_batch_size=2,\n",
    "        num_train_epochs=1,\n",
    "        learning_rate=2e-4,\n",
    "        logging_steps=10,\n",
    "        fp16=True,\n",
    "        save_strategy=\"epoch\"\n",
    "    )\n",
    "\n",
    "    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    model.save_pretrained(f\"./adapter_{domain_name}\")\n",
    "    tokenizer.save_pretrained(f\"./adapter_{domain_name}\")\n",
    "    return f\"./adapter_{domain_name}\"\n",
    "\n",
    "# --------------------------\n",
    "# SECTION 4: Adapter Router\n",
    "# --------------------------\n",
    "def router(domain):\n",
    "    if domain == \"medical\":\n",
    "        return \"./adapter_medical\"\n",
    "    elif domain == \"legal\":\n",
    "        return \"./adapter_legal\"\n",
    "    elif domain == \"finance\":\n",
    "        return \"./adapter_finance\"\n",
    "    else:\n",
    "        raise ValueError(\"Unknown domain\")\n",
    "\n",
    "# --------------------------\n",
    "# SECTION 5: Load Adapter Dynamically\n",
    "# --------------------------\n",
    "def load_model_with_adapter(base_model_name, adapter_path):\n",
    "    config = PeftConfig.from_pretrained(adapter_path)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model_name,\n",
    "        # load_in_8bit=True,\n",
    "        device_map={\"\": 0},\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    model = PeftModel.from_pretrained(model, adapter_path)\n",
    "    return model\n",
    "\n",
    "# --------------------------\n",
    "# SECTION 6: Merge Adapters (Optional)\n",
    "# --------------------------\n",
    "def merge_adapter(model):\n",
    "    print(\"Merging adapter with base model...\")\n",
    "    merged_model = model.merge_and_unload()\n",
    "    merged_model.save_pretrained(\"./merged_model\")\n",
    "    return merged_model\n",
    "\n",
    "# --------------------------\n",
    "# SECTION 7: Main Flow\n",
    "# --------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Train medical adapter if not exists\n",
    "    if not os.path.exists(\"./adapter_medical\"):\n",
    "        tokenized_dataset = load_tokenized_dataset(tokenizer, domain=\"medical\")\n",
    "        train_and_save_adapter(\"medical\", tokenized_dataset, tokenizer)\n",
    "\n",
    "    # Router selects adapter path\n",
    "    adapter_path = router(\"medical\")\n",
    "    model = load_model_with_adapter(model_name, adapter_path)\n",
    "\n",
    "    # Optionally merge adapter\n",
    "    # model = merge_adapter(model)\n",
    "\n",
    "    print(\"✅ Model loaded with domain-specific adapter\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
